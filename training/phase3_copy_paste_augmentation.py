#!/usr/bin/env python3
"""
ğŸ¯ Phase 3: Copy-Paste å¢å¼·ç­–ç•¥
================================

ç›®æ¨™ï¼šç„¡éœ€ LilyPondï¼Œç›´æ¥å¾ç¾æœ‰è¨“ç·´æ•¸æ“šå¢å¼·ç¨€æœ‰é¡åˆ¥

åŸç†ï¼š
1. å¾ç¾æœ‰è¨“ç·´æ•¸æ“šä¸­æå–ç¨€æœ‰é¡åˆ¥çš„ç¬¦è™Ÿå€åŸŸ (crop)
2. å°‡é€™äº›ç¬¦è™Ÿè²¼åˆ°å…¶ä»–æ¨‚è­œåœ–ç‰‡çš„é©ç•¶ä½ç½®
3. è‡ªå‹•æ›´æ–°æ¨™è¨»

å„ªå‹¢ï¼š
- ä¸éœ€è¦å¤–éƒ¨å·¥å…·
- ç¬¦è™ŸçœŸå¯¦ï¼ˆä¾†è‡ªçœŸå¯¦æ•¸æ“šï¼‰
- æ¨™è¨»è‡ªå‹•æ­£ç¢º

ä½¿ç”¨æ–¹å¼ï¼š
    # 1. æå–ç¨€æœ‰é¡åˆ¥ç¬¦è™Ÿ
    python phase3_copy_paste_augmentation.py --extract-symbols

    # 2. ç”Ÿæˆå¢å¼·æ•¸æ“š
    python phase3_copy_paste_augmentation.py --augment-all

    # 3. æº–å‚™è¨“ç·´æ•¸æ“šé›†
    python phase3_copy_paste_augmentation.py --prepare-dataset
"""

import os
import sys
import json
import random
import shutil
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
from collections import defaultdict
import argparse

try:
    import cv2
    import numpy as np
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    print("âš ï¸ OpenCV æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install opencv-python")


# ============== ç“¶é ¸é¡åˆ¥é…ç½® ==============

BOTTLENECK_CONFIG = {
    # class_id: (name, target_augmented_count, min_crop_size)
    16: ("accidental_double_sharp", 5000, 20),
    17: ("accidental_double_flat", 5000, 20),
    24: ("barline_double", 3000, 15),
    31: ("dynamic_loud", 5000, 25),
    29: ("fermata", 3000, 25),
    25: ("barline_final", 2000, 15),
    5:  ("flag_16th", 4000, 15),
    6:  ("flag_32nd", 4000, 15),
    15: ("accidental_natural", 3000, 20),
    12: ("clef_tenor", 3000, 30),
    30: ("dynamic_soft", 2000, 25),
    8:  ("tie", 2000, 30),
    23: ("barline", 2000, 10),
    7:  ("augmentation_dot", 2000, 8),
}


@dataclass
class SymbolCrop:
    """æå–çš„ç¬¦è™Ÿè£å‰ª"""
    class_id: int
    class_name: str
    source_image: str
    bbox_normalized: Tuple[float, float, float, float]  # x_center, y_center, w, h
    crop_path: Optional[Path] = None


class CopyPasteAugmentor:
    """Copy-Paste å¢å¼·å™¨"""

    def __init__(
        self,
        source_dataset: Path,
        output_dir: Path,
        crops_dir: Optional[Path] = None
    ):
        self.source_dataset = Path(source_dataset)
        self.output_dir = Path(output_dir)
        self.crops_dir = crops_dir or (output_dir / "symbol_crops")

        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.crops_dir.mkdir(parents=True, exist_ok=True)

        # ç¬¦è™Ÿåº«ï¼šclass_id -> List[SymbolCrop]
        self.symbol_bank: Dict[int, List[SymbolCrop]] = defaultdict(list)

        # çµ±è¨ˆ
        self.stats = defaultdict(int)

    def load_yolo_label(self, label_path: Path) -> List[Tuple[int, float, float, float, float]]:
        """è¼‰å…¥ YOLO æ ¼å¼æ¨™è¨»"""
        labels = []
        if not label_path.exists():
            return labels

        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    labels.append((class_id, x_center, y_center, width, height))

        return labels

    def save_yolo_label(
        self,
        label_path: Path,
        labels: List[Tuple[int, float, float, float, float]]
    ):
        """ä¿å­˜ YOLO æ ¼å¼æ¨™è¨»"""
        with open(label_path, 'w') as f:
            for class_id, x, y, w, h in labels:
                f.write(f"{class_id} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\n")

    def extract_symbol_crops(self, target_classes: Optional[List[int]] = None):
        """
        å¾è¨“ç·´æ•¸æ“šä¸­æå–ç¨€æœ‰é¡åˆ¥çš„ç¬¦è™Ÿè£å‰ª

        Args:
            target_classes: ç›®æ¨™é¡åˆ¥ ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰ç“¶é ¸é¡åˆ¥
        """
        if not HAS_CV2:
            print("âŒ éœ€è¦ OpenCV: pip install opencv-python")
            return

        if target_classes is None:
            target_classes = list(BOTTLENECK_CONFIG.keys())

        print("\n" + "="*60)
        print("æå–ç¨€æœ‰é¡åˆ¥ç¬¦è™Ÿ")
        print("="*60)

        images_dir = self.source_dataset / "train" / "images"
        labels_dir = self.source_dataset / "train" / "labels"

        if not images_dir.exists():
            print(f"âŒ åœ–ç‰‡ç›®éŒ„ä¸å­˜åœ¨: {images_dir}")
            return

        # ç‚ºæ¯å€‹ç›®æ¨™é¡åˆ¥å‰µå»ºå­ç›®éŒ„
        for class_id in target_classes:
            class_name = BOTTLENECK_CONFIG[class_id][0]
            (self.crops_dir / class_name).mkdir(exist_ok=True)

        # éæ­·æ‰€æœ‰è¨“ç·´åœ–ç‰‡
        image_files = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg"))
        print(f"æƒæ {len(image_files)} å¼µè¨“ç·´åœ–ç‰‡...")

        for img_path in image_files:
            label_path = labels_dir / f"{img_path.stem}.txt"
            labels = self.load_yolo_label(label_path)

            if not labels:
                continue

            # éæ¿¾å‡ºç›®æ¨™é¡åˆ¥
            target_labels = [(l, idx) for idx, l in enumerate(labels) if l[0] in target_classes]

            if not target_labels:
                continue

            # è®€å–åœ–ç‰‡
            img = cv2.imread(str(img_path))
            if img is None:
                continue

            h, w = img.shape[:2]

            for (class_id, x_center, y_center, box_w, box_h), idx in target_labels:
                class_name, _, min_size = BOTTLENECK_CONFIG[class_id]

                # è¨ˆç®—åƒç´ åº§æ¨™
                x1 = int((x_center - box_w / 2) * w)
                y1 = int((y_center - box_h / 2) * h)
                x2 = int((x_center + box_w / 2) * w)
                y2 = int((y_center + box_h / 2) * h)

                # ç¢ºä¿åœ¨åœ–ç‰‡ç¯„åœå…§
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(w, x2)
                y2 = min(h, y2)

                # æª¢æŸ¥å¤§å°
                crop_w = x2 - x1
                crop_h = y2 - y1

                if crop_w < min_size or crop_h < min_size:
                    continue

                # è£å‰ªç¬¦è™Ÿ
                crop = img[y1:y2, x1:x2]

                if crop.size == 0:
                    continue

                # ä¿å­˜è£å‰ª
                crop_filename = f"{img_path.stem}_{idx}_{class_id}.png"
                crop_path = self.crops_dir / class_name / crop_filename

                cv2.imwrite(str(crop_path), crop)

                # è¨˜éŒ„åˆ°ç¬¦è™Ÿåº«
                symbol = SymbolCrop(
                    class_id=class_id,
                    class_name=class_name,
                    source_image=str(img_path),
                    bbox_normalized=(x_center, y_center, box_w, box_h),
                    crop_path=crop_path
                )
                self.symbol_bank[class_id].append(symbol)
                self.stats[class_id] += 1

        # æ‰“å°çµ±è¨ˆ
        print("\nç¬¦è™Ÿæå–çµ±è¨ˆ:")
        print("-" * 50)
        for class_id in sorted(target_classes):
            class_name = BOTTLENECK_CONFIG[class_id][0]
            count = self.stats[class_id]
            print(f"  Class {class_id:2d} ({class_name:25s}): {count:5d} å€‹ç¬¦è™Ÿ")

        # ä¿å­˜ç¬¦è™Ÿåº«ç´¢å¼•
        self.save_symbol_bank_index()

    def save_symbol_bank_index(self):
        """ä¿å­˜ç¬¦è™Ÿåº«ç´¢å¼•"""
        index = {}
        for class_id, symbols in self.symbol_bank.items():
            index[class_id] = [
                {
                    "class_name": s.class_name,
                    "source_image": s.source_image,
                    "bbox_normalized": s.bbox_normalized,
                    "crop_path": str(s.crop_path) if s.crop_path else None
                }
                for s in symbols
            ]

        index_path = self.crops_dir / "symbol_bank_index.json"
        with open(index_path, 'w') as f:
            json.dump(index, f, indent=2)

        print(f"\nâœ… ç¬¦è™Ÿåº«ç´¢å¼•å·²ä¿å­˜: {index_path}")

    def load_symbol_bank_index(self):
        """è¼‰å…¥ç¬¦è™Ÿåº«ç´¢å¼•"""
        index_path = self.crops_dir / "symbol_bank_index.json"

        if not index_path.exists():
            print(f"âš ï¸ ç¬¦è™Ÿåº«ç´¢å¼•ä¸å­˜åœ¨: {index_path}")
            print("   è«‹å…ˆåŸ·è¡Œ: --extract-symbols")
            return False

        with open(index_path, 'r') as f:
            index = json.load(f)

        for class_id_str, symbols in index.items():
            class_id = int(class_id_str)
            for s in symbols:
                crop_path = Path(s["crop_path"]) if s["crop_path"] else None
                if crop_path and crop_path.exists():
                    symbol = SymbolCrop(
                        class_id=class_id,
                        class_name=s["class_name"],
                        source_image=s["source_image"],
                        bbox_normalized=tuple(s["bbox_normalized"]),
                        crop_path=crop_path
                    )
                    self.symbol_bank[class_id].append(symbol)

        print(f"âœ… è¼‰å…¥ç¬¦è™Ÿåº«: {sum(len(v) for v in self.symbol_bank.values())} å€‹ç¬¦è™Ÿ")
        return True

    def paste_symbol(
        self,
        base_img: np.ndarray,
        symbol_crop: np.ndarray,
        target_position: Tuple[float, float],
        scale: float = 1.0
    ) -> Tuple[np.ndarray, Tuple[float, float, float, float]]:
        """
        å°‡ç¬¦è™Ÿè²¼åˆ°åœ–ç‰‡ä¸Š

        Args:
            base_img: åŸºåº•åœ–ç‰‡
            symbol_crop: ç¬¦è™Ÿè£å‰ª
            target_position: ç›®æ¨™ä½ç½® (normalized x, y)
            scale: ç¸®æ”¾æ¯”ä¾‹

        Returns:
            (ä¿®æ”¹å¾Œçš„åœ–ç‰‡, æ–°çš„ bbox)
        """
        h, w = base_img.shape[:2]
        crop_h, crop_w = symbol_crop.shape[:2]

        # ç¸®æ”¾ç¬¦è™Ÿ
        if scale != 1.0:
            new_w = int(crop_w * scale)
            new_h = int(crop_h * scale)
            symbol_crop = cv2.resize(symbol_crop, (new_w, new_h))
            crop_h, crop_w = symbol_crop.shape[:2]

        # è¨ˆç®—è²¼ä¸Šä½ç½®ï¼ˆåƒç´ ï¼‰
        target_x = int(target_position[0] * w)
        target_y = int(target_position[1] * h)

        # è¨ˆç®—å·¦ä¸Šè§’
        x1 = target_x - crop_w // 2
        y1 = target_y - crop_h // 2

        # ç¢ºä¿åœ¨åœ–ç‰‡ç¯„åœå…§
        if x1 < 0 or y1 < 0 or x1 + crop_w > w or y1 + crop_h > h:
            # èª¿æ•´ä½ç½®
            x1 = max(0, min(x1, w - crop_w))
            y1 = max(0, min(y1, h - crop_h))

        # è²¼ä¸Šç¬¦è™Ÿï¼ˆç°¡å–®è¦†è“‹ï¼Œå¯æ”¹é€²ç‚º alpha blendingï¼‰
        result = base_img.copy()

        # ä½¿ç”¨æ›´å¥½çš„æ··åˆæ–¹å¼
        if symbol_crop.shape[2] == 4:  # æœ‰ alpha é€šé“
            alpha = symbol_crop[:, :, 3] / 255.0
            for c in range(3):
                result[y1:y1+crop_h, x1:x1+crop_w, c] = (
                    alpha * symbol_crop[:, :, c] +
                    (1 - alpha) * result[y1:y1+crop_h, x1:x1+crop_w, c]
                )
        else:
            # ç°¡å–®è¦†è“‹ï¼Œç•¥å¾®é€æ˜è™•ç†ç™½è‰²èƒŒæ™¯
            mask = cv2.cvtColor(symbol_crop, cv2.COLOR_BGR2GRAY)
            mask = (mask < 250).astype(np.float32)  # éç™½è‰²å€åŸŸ
            mask = cv2.GaussianBlur(mask, (3, 3), 0)

            for c in range(3):
                result[y1:y1+crop_h, x1:x1+crop_w, c] = (
                    mask * symbol_crop[:, :, c] +
                    (1 - mask) * result[y1:y1+crop_h, x1:x1+crop_w, c]
                ).astype(np.uint8)

        # è¨ˆç®—æ–°çš„ bbox (normalized)
        new_x_center = (x1 + crop_w / 2) / w
        new_y_center = (y1 + crop_h / 2) / h
        new_w = crop_w / w
        new_h = crop_h / h

        return result, (new_x_center, new_y_center, new_w, new_h)

    def augment_image(
        self,
        image_path: Path,
        label_path: Path,
        output_image_path: Path,
        output_label_path: Path,
        target_class: int,
        num_pastes: int = 3
    ) -> bool:
        """
        å°å–®å¼µåœ–ç‰‡é€²è¡Œ Copy-Paste å¢å¼·

        Args:
            image_path: è¼¸å…¥åœ–ç‰‡è·¯å¾‘
            label_path: è¼¸å…¥æ¨™è¨»è·¯å¾‘
            output_image_path: è¼¸å‡ºåœ–ç‰‡è·¯å¾‘
            output_label_path: è¼¸å‡ºæ¨™è¨»è·¯å¾‘
            target_class: è¦å¢å¼·çš„ç›®æ¨™é¡åˆ¥
            num_pastes: è²¼ä¸Šæ¬¡æ•¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not HAS_CV2:
            return False

        # æª¢æŸ¥ç¬¦è™Ÿåº«
        if target_class not in self.symbol_bank or len(self.symbol_bank[target_class]) == 0:
            return False

        # è®€å–åœ–ç‰‡
        img = cv2.imread(str(image_path))
        if img is None:
            return False

        h, w = img.shape[:2]

        # è®€å–ç¾æœ‰æ¨™è¨»
        labels = self.load_yolo_label(label_path)

        # è¤‡è£½åœ–ç‰‡
        result_img = img.copy()
        new_labels = list(labels)

        # è²¼ä¸Šç¬¦è™Ÿ
        for _ in range(num_pastes):
            # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ç¬¦è™Ÿ
            symbol = random.choice(self.symbol_bank[target_class])

            if symbol.crop_path is None or not symbol.crop_path.exists():
                continue

            # è®€å–ç¬¦è™Ÿè£å‰ª
            crop = cv2.imread(str(symbol.crop_path))
            if crop is None:
                continue

            # éš¨æ©Ÿé¸æ“‡ä½ç½®ï¼ˆåœ¨äº”ç·šè­œå€åŸŸï¼‰
            target_x = random.uniform(0.1, 0.9)
            target_y = random.uniform(0.2, 0.8)

            # éš¨æ©Ÿç¸®æ”¾
            scale = random.uniform(0.8, 1.2)

            # è²¼ä¸Š
            result_img, new_bbox = self.paste_symbol(
                result_img, crop, (target_x, target_y), scale
            )

            # æ·»åŠ æ–°æ¨™è¨»
            new_labels.append((target_class, *new_bbox))

        # ä¿å­˜çµæœ
        cv2.imwrite(str(output_image_path), result_img)
        self.save_yolo_label(output_label_path, new_labels)

        return True

    def augment_dataset(
        self,
        target_classes: Optional[List[int]] = None,
        samples_per_class: Optional[Dict[int, int]] = None
    ):
        """
        å¢å¼·æ•´å€‹æ•¸æ“šé›†

        Args:
            target_classes: ç›®æ¨™é¡åˆ¥åˆ—è¡¨
            samples_per_class: æ¯å€‹é¡åˆ¥çš„ç›®æ¨™å¢å¼·æ•¸é‡
        """
        if not HAS_CV2:
            print("âŒ éœ€è¦ OpenCV: pip install opencv-python")
            return

        # è¼‰å…¥ç¬¦è™Ÿåº«
        if not self.symbol_bank:
            if not self.load_symbol_bank_index():
                return

        if target_classes is None:
            target_classes = list(BOTTLENECK_CONFIG.keys())

        if samples_per_class is None:
            samples_per_class = {
                class_id: BOTTLENECK_CONFIG[class_id][1]
                for class_id in target_classes
            }

        print("\n" + "="*60)
        print("Copy-Paste æ•¸æ“šå¢å¼·")
        print("="*60)

        # éæ¿¾æœ‰è¶³å¤ ç¬¦è™Ÿçš„é¡åˆ¥
        available_classes = [
            c for c in target_classes
            if c in self.symbol_bank and len(self.symbol_bank[c]) >= 10
        ]

        if not available_classes:
            print("âŒ æ²’æœ‰è¶³å¤ çš„ç¬¦è™Ÿé€²è¡Œå¢å¼·")
            print("   è«‹å…ˆåŸ·è¡Œ: --extract-symbols")
            return

        print(f"å¯ç”¨é¡åˆ¥: {len(available_classes)}/{len(target_classes)}")

        # æº–å‚™è¼¸å‡ºç›®éŒ„
        output_images = self.output_dir / "augmented" / "images"
        output_labels = self.output_dir / "augmented" / "labels"
        output_images.mkdir(parents=True, exist_ok=True)
        output_labels.mkdir(parents=True, exist_ok=True)

        # ç²å–åŸºåº•åœ–ç‰‡åˆ—è¡¨
        source_images = self.source_dataset / "train" / "images"
        base_images = list(source_images.glob("*.png")) + list(source_images.glob("*.jpg"))

        if not base_images:
            print(f"âŒ æ²’æœ‰åŸºåº•åœ–ç‰‡: {source_images}")
            return

        print(f"åŸºåº•åœ–ç‰‡: {len(base_images)} å¼µ")

        # ç‚ºæ¯å€‹é¡åˆ¥ç”Ÿæˆå¢å¼·æ•¸æ“š
        for class_id in available_classes:
            class_name = BOTTLENECK_CONFIG[class_id][0]
            target_count = samples_per_class.get(class_id, 1000)
            available_symbols = len(self.symbol_bank[class_id])

            print(f"\nè™•ç† Class {class_id} ({class_name}):")
            print(f"  å¯ç”¨ç¬¦è™Ÿ: {available_symbols}")
            print(f"  ç›®æ¨™æ•¸é‡: {target_count}")

            success_count = 0

            for i in range(target_count):
                # éš¨æ©Ÿé¸æ“‡åŸºåº•åœ–ç‰‡
                base_img_path = random.choice(base_images)
                base_label_path = (
                    self.source_dataset / "train" / "labels" /
                    f"{base_img_path.stem}.txt"
                )

                # è¼¸å‡ºè·¯å¾‘
                output_name = f"aug_{class_name}_{i:05d}"
                out_img = output_images / f"{output_name}.png"
                out_lbl = output_labels / f"{output_name}.txt"

                # å¢å¼·
                num_pastes = random.randint(1, 3)
                if self.augment_image(
                    base_img_path, base_label_path,
                    out_img, out_lbl,
                    class_id, num_pastes
                ):
                    success_count += 1

                if (i + 1) % 500 == 0:
                    print(f"  é€²åº¦: {i+1}/{target_count}")

            self.stats[class_id] = success_count
            print(f"  âœ… å®Œæˆ: {success_count}/{target_count}")

        # çµ±è¨ˆç¸½çµ
        print("\n" + "="*60)
        print("å¢å¼·çµ±è¨ˆ")
        print("="*60)
        for class_id in available_classes:
            class_name = BOTTLENECK_CONFIG[class_id][0]
            count = self.stats[class_id]
            print(f"  Class {class_id:2d} ({class_name:25s}): {count:5d}")

        print(f"\n  ç¸½è¨ˆ: {sum(self.stats.values()):,} å¼µå¢å¼·åœ–ç‰‡")
        print(f"  ä¿å­˜æ–¼: {self.output_dir / 'augmented'}")


def prepare_phase3_dataset(
    original_dataset: Path,
    augmented_dir: Path,
    output_dir: Path
):
    """
    æº–å‚™ Phase 3 æ··åˆæ•¸æ“šé›†

    åˆä½µï¼šåŸå§‹è¨“ç·´æ•¸æ“š + Copy-Paste å¢å¼·æ•¸æ“š
    """
    print("\n" + "="*60)
    print("æº–å‚™ Phase 3 æ•¸æ“šé›†")
    print("="*60)

    output_dir = Path(output_dir)
    output_train_images = output_dir / "train" / "images"
    output_train_labels = output_dir / "train" / "labels"
    output_val_images = output_dir / "val" / "images"
    output_val_labels = output_dir / "val" / "labels"

    for d in [output_train_images, output_train_labels, output_val_images, output_val_labels]:
        d.mkdir(parents=True, exist_ok=True)

    # 1. è¤‡è£½åŸå§‹è¨“ç·´æ•¸æ“š
    print("\n1. è¤‡è£½åŸå§‹è¨“ç·´æ•¸æ“š...")
    orig_train_images = original_dataset / "train" / "images"
    orig_train_labels = original_dataset / "train" / "labels"

    if orig_train_images.exists():
        for img in orig_train_images.glob("*"):
            shutil.copy2(img, output_train_images / img.name)
        for lbl in orig_train_labels.glob("*"):
            shutil.copy2(lbl, output_train_labels / lbl.name)
        print(f"   è¤‡è£½äº† {len(list(orig_train_images.glob('*')))} å¼µåŸå§‹è¨“ç·´åœ–ç‰‡")

    # 2. è¤‡è£½åŸå§‹é©—è­‰æ•¸æ“š
    print("\n2. è¤‡è£½åŸå§‹é©—è­‰æ•¸æ“š...")
    orig_val_images = original_dataset / "val" / "images"
    orig_val_labels = original_dataset / "val" / "labels"

    if orig_val_images.exists():
        for img in orig_val_images.glob("*"):
            shutil.copy2(img, output_val_images / img.name)
        for lbl in orig_val_labels.glob("*"):
            shutil.copy2(lbl, output_val_labels / lbl.name)
        print(f"   è¤‡è£½äº† {len(list(orig_val_images.glob('*')))} å¼µåŸå§‹é©—è­‰åœ–ç‰‡")

    # 3. æ·»åŠ å¢å¼·æ•¸æ“šåˆ°è¨“ç·´é›†
    print("\n3. æ·»åŠ å¢å¼·æ•¸æ“š...")
    aug_images = augmented_dir / "images"
    aug_labels = augmented_dir / "labels"

    if aug_images.exists():
        aug_count = 0
        for img in aug_images.glob("*"):
            shutil.copy2(img, output_train_images / img.name)
            aug_count += 1
        for lbl in aug_labels.glob("*"):
            shutil.copy2(lbl, output_train_labels / lbl.name)
        print(f"   æ·»åŠ äº† {aug_count} å¼µå¢å¼·åœ–ç‰‡")

    # 4. å‰µå»ºæ•¸æ“šé›†é…ç½®
    print("\n4. å‰µå»ºæ•¸æ“šé›†é…ç½®...")

    config = f"""# Phase 3: Copy-Paste å¢å¼·æ•¸æ“šé›†
path: {output_dir.absolute()}
train: train/images
val: val/images

nc: 33

names:
  0: notehead_filled
  1: notehead_hollow
  2: stem
  3: beam
  4: flag_8th
  5: flag_16th
  6: flag_32nd
  7: augmentation_dot
  8: tie
  9: clef_treble
  10: clef_bass
  11: clef_alto
  12: clef_tenor
  13: accidental_sharp
  14: accidental_flat
  15: accidental_natural
  16: accidental_double_sharp
  17: accidental_double_flat
  18: rest_whole
  19: rest_half
  20: rest_quarter
  21: rest_8th
  22: rest_16th
  23: barline
  24: barline_double
  25: barline_final
  26: barline_repeat
  27: time_signature
  28: key_signature
  29: fermata
  30: dynamic_soft
  31: dynamic_loud
  32: ledger_line
"""

    yaml_path = output_dir / "harmony_phase3.yaml"
    with open(yaml_path, 'w') as f:
        f.write(config)

    print(f"\nâœ… æ•¸æ“šé›†é…ç½®: {yaml_path}")

    # çµ±è¨ˆ
    final_train = len(list(output_train_images.glob("*")))
    final_val = len(list(output_val_images.glob("*")))
    print(f"\næœ€çµ‚æ•¸æ“šé›†çµ±è¨ˆ:")
    print(f"  è¨“ç·´é›†: {final_train:,} å¼µ")
    print(f"  é©—è­‰é›†: {final_val:,} å¼µ")

    return yaml_path


def create_phase3_train_script(output_dir: Path):
    """å‰µå»º Phase 3 è¨“ç·´è…³æœ¬"""

    script = '''#!/usr/bin/env python3
"""
Phase 3 è¨“ç·´è…³æœ¬ - Copy-Paste å¢å¼·ç‰ˆ
=====================================

å¾ Phase 2 best.pt ç¹¼çºŒè¨“ç·´ï¼Œä½¿ç”¨å¢å¼·å¾Œçš„æ•¸æ“šé›†
"""
from ultralytics import YOLO
from pathlib import Path
import os

def main():
    # åˆ‡æ›åˆ°è¨“ç·´ç›®éŒ„
    os.chdir(Path(__file__).parent)

    print("="*60)
    print("Phase 3: Copy-Paste å¢å¼·è¨“ç·´")
    print("="*60)

    # è¼‰å…¥ Phase 2 æœ€ä½³æ¨¡å‹
    model = YOLO('harmony_omr_v2_phase2/balanced_training/weights/best.pt')

    # é–‹å§‹è¨“ç·´
    results = model.train(
        # æ•¸æ“šé›†
        data='datasets/yolo_harmony_v2_phase3/harmony_phase3.yaml',

        # è¨“ç·´åƒæ•¸
        epochs=200,
        batch=16,
        imgsz=640,
        patience=50,  # æ›´é•·çš„è€å¿ƒ

        # å­¸ç¿’ç‡ï¼ˆå¾®èª¿æ¨¡å¼ï¼‰
        lr0=0.0005,
        lrf=0.0001,

        # æ•¸æ“šå¢å¼·ï¼ˆæ›´æº«å’Œï¼Œå› ç‚ºå·²æœ‰ Copy-Pasteï¼‰
        mosaic=0.3,
        mixup=0.1,
        copy_paste=0.0,  # é—œé–‰ï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“æ‰‹å‹•åšäº†

        hsv_h=0.01,
        hsv_s=0.3,
        hsv_v=0.3,
        degrees=3.0,
        translate=0.05,
        scale=0.3,

        # è¼¸å‡º
        project='harmony_omr_v2_phase3',
        name='copypaste_enhanced',
        exist_ok=True,

        # å…¶ä»–
        cos_lr=True,
        amp=True,
        verbose=True,
        save_period=10,
    )

    print("\\n" + "="*60)
    print("Phase 3 è¨“ç·´å®Œæˆï¼")
    print("="*60)
    print(f"æœ€ä½³æ¨¡å‹: harmony_omr_v2_phase3/copypaste_enhanced/weights/best.pt")

    return results


if __name__ == '__main__':
    main()
'''

    script_path = output_dir / "yolo12_train_phase3.py"
    with open(script_path, 'w') as f:
        f.write(script)

    print(f"âœ… è¨“ç·´è…³æœ¬: {script_path}")
    return script_path


# ============== ä¸»ç¨‹åº ==============

def main():
    parser = argparse.ArgumentParser(description='Phase 3: Copy-Paste å¢å¼·')

    parser.add_argument('--extract-symbols', action='store_true',
                       help='å¾è¨“ç·´æ•¸æ“šæå–ç¨€æœ‰é¡åˆ¥ç¬¦è™Ÿ')
    parser.add_argument('--augment-all', action='store_true',
                       help='ç”Ÿæˆæ‰€æœ‰ç“¶é ¸é¡åˆ¥çš„å¢å¼·æ•¸æ“š')
    parser.add_argument('--augment-class', type=int,
                       help='ç”Ÿæˆç‰¹å®šé¡åˆ¥çš„å¢å¼·æ•¸æ“š')
    parser.add_argument('--count', type=int, default=1000,
                       help='ç”Ÿæˆæ•¸é‡')
    parser.add_argument('--prepare-dataset', action='store_true',
                       help='æº–å‚™ Phase 3 æ··åˆæ•¸æ“šé›†')
    parser.add_argument('--create-script', action='store_true',
                       help='å‰µå»ºè¨“ç·´è…³æœ¬')
    parser.add_argument('--full-pipeline', action='store_true',
                       help='åŸ·è¡Œå®Œæ•´æµç¨‹ï¼šæå–â†’å¢å¼·â†’æº–å‚™æ•¸æ“šé›†')

    parser.add_argument('--source-dataset', type=str,
                       default='datasets/yolo_harmony_v2_phase2',
                       help='åŸå§‹æ•¸æ“šé›†è·¯å¾‘')
    parser.add_argument('--output-dir', type=str,
                       default='datasets/yolo_harmony_v2_phase3_copypaste',
                       help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--status', action='store_true',
                       help='é¡¯ç¤ºç“¶é ¸é¡åˆ¥ç‹€æ…‹')

    args = parser.parse_args()

    # åˆ‡æ›åˆ°è¨“ç·´ç›®éŒ„
    training_dir = Path(__file__).parent
    os.chdir(training_dir)

    source_dataset = Path(args.source_dataset)
    output_dir = Path(args.output_dir)

    if args.status:
        print("\n" + "="*70)
        print("ç“¶é ¸é¡åˆ¥é…ç½®")
        print("="*70)
        print(f"{'ID':>3} {'åç¨±':25s} {'ç›®æ¨™å¢å¼·æ•¸':>12} {'æœ€å°è£å‰ª':>10}")
        print("-"*55)

        for class_id, (name, target, min_size) in sorted(BOTTLENECK_CONFIG.items()):
            print(f"{class_id:>3} {name:25s} {target:>12,} {min_size:>10}")

        return

    if args.extract_symbols:
        augmentor = CopyPasteAugmentor(source_dataset, output_dir)
        augmentor.extract_symbol_crops()
        return

    if args.augment_all:
        augmentor = CopyPasteAugmentor(source_dataset, output_dir)
        augmentor.augment_dataset()
        return

    if args.augment_class is not None:
        augmentor = CopyPasteAugmentor(source_dataset, output_dir)
        augmentor.augment_dataset(
            target_classes=[args.augment_class],
            samples_per_class={args.augment_class: args.count}
        )
        return

    if args.prepare_dataset:
        augmented_dir = output_dir / "augmented"
        final_dataset = Path("datasets/yolo_harmony_v2_phase3")
        prepare_phase3_dataset(source_dataset, augmented_dir, final_dataset)
        create_phase3_train_script(training_dir)
        return

    if args.create_script:
        create_phase3_train_script(training_dir)
        return

    if args.full_pipeline:
        print("\n" + "="*70)
        print("Phase 3 å®Œæ•´æµç¨‹")
        print("="*70)

        # Step 1: æå–ç¬¦è™Ÿ
        print("\n[Step 1/3] æå–ç¨€æœ‰é¡åˆ¥ç¬¦è™Ÿ...")
        augmentor = CopyPasteAugmentor(source_dataset, output_dir)
        augmentor.extract_symbol_crops()

        # Step 2: ç”Ÿæˆå¢å¼·æ•¸æ“š
        print("\n[Step 2/3] ç”Ÿæˆå¢å¼·æ•¸æ“š...")
        augmentor.augment_dataset()

        # Step 3: æº–å‚™æ•¸æ“šé›†
        print("\n[Step 3/3] æº–å‚™æ··åˆæ•¸æ“šé›†...")
        augmented_dir = output_dir / "augmented"
        final_dataset = Path("datasets/yolo_harmony_v2_phase3")
        prepare_phase3_dataset(source_dataset, augmented_dir, final_dataset)

        # å‰µå»ºè¨“ç·´è…³æœ¬
        create_phase3_train_script(training_dir)

        print("\n" + "="*70)
        print("Phase 3 æº–å‚™å®Œæˆï¼")
        print("="*70)
        print("""
ä¸‹ä¸€æ­¥ï¼šé–‹å§‹è¨“ç·´
    source venv_yolo12/bin/activate
    python yolo12_train_phase3.py
""")
        return

    # é»˜èªï¼šé¡¯ç¤ºå¹«åŠ©
    parser.print_help()
    print("\n" + "="*60)
    print("Phase 3 Copy-Paste å¢å¼·å·¥ä½œæµç¨‹")
    print("="*60)
    print("""
å®Œæ•´æµç¨‹ï¼ˆæ¨è–¦ï¼‰ï¼š
    python phase3_copy_paste_augmentation.py --full-pipeline

æˆ–åˆ†æ­¥åŸ·è¡Œï¼š
    1. æå–ç¨€æœ‰é¡åˆ¥ç¬¦è™Ÿ:
       python phase3_copy_paste_augmentation.py --extract-symbols

    2. ç”Ÿæˆå¢å¼·æ•¸æ“š:
       python phase3_copy_paste_augmentation.py --augment-all

    3. æº–å‚™æ•¸æ“šé›†å’Œè¨“ç·´è…³æœ¬:
       python phase3_copy_paste_augmentation.py --prepare-dataset

    4. é–‹å§‹è¨“ç·´:
       source venv_yolo12/bin/activate
       python yolo12_train_phase3.py
""")


if __name__ == '__main__':
    main()

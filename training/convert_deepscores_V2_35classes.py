#!/usr/bin/env python3
"""
DeepScoresV2 â†’ YOLO æ¥µè‡´ä¸¦è¡Œç‰ˆæœ¬
çœŸæ­£ä½¿ç”¨å…¨éƒ¨ 24 æ ¸å¿ƒï¼

å„ªåŒ–ç­–ç•¥ï¼š
1. é å…ˆè¼‰å…¥æ‰€æœ‰ JSON åˆ°è¨˜æ†¶é«”ï¼ˆé¿å…é‡è¤‡è®€å–ï¼‰
2. ä½¿ç”¨ chunksize æ‰¹æ¬¡è™•ç†
3. æ¸›å°‘é€²ç¨‹é–“é€šè¨Šé–‹éŠ·
4. ä½¿ç”¨ ProcessPoolExecutor æ›¿ä»£ Pool
"""

import json
import shutil
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
import numpy as np

from deepscores_to_harmony_mapping_v2_35classes import get_harmony_class_id

# é…ç½®
DEEPSCORES_DIR = Path("datasets/ds2_dense")
OUTPUT_DIR = Path("datasets/yolo_harmony")
NUM_WORKERS = 24
CHUNK_SIZE = 10  # æ¯å€‹ worker ä¸€æ¬¡è™•ç† 10 å¼µåœ–

def convert_bbox_to_yolo(bbox, img_width, img_height):
    """bbox è½‰æ›ï¼ˆå·²ä¿®å¾©é‚Šç•Œå•é¡Œï¼‰"""
    x, y, w, h = bbox

    # ç¢ºä¿ bbox åœ¨åœ–ç‰‡ç¯„åœå…§
    x = max(0, min(x, img_width))
    y = max(0, min(y, img_height))
    w = max(1, min(w, img_width - x))
    h = max(1, min(h, img_height - y))

    # æ­¸ä¸€åŒ–
    x_center = (x + w / 2) / img_width
    y_center = (y + h / 2) / img_height
    width = w / img_width
    height = h / img_height

    # æœ€çµ‚è£åˆ‡
    x_center = max(0.0, min(1.0, x_center))
    y_center = max(0.0, min(1.0, y_center))
    width = max(0.0, min(1.0, width))
    height = max(0.0, min(1.0, height))

    return x_center, y_center, width, height

def process_image_batch(args):
    """
    æ‰¹æ¬¡è™•ç†å¤šå¼µåœ–ç‰‡ï¼ˆæ¸›å°‘é€²ç¨‹å•Ÿå‹•é–‹éŠ·ï¼‰

    Args:
        args: (image_batch, annotations_dict, images_dir, labels_dir)

    Returns:
        [(success, image_id, num_annotations), ...]
    """
    image_batch, annotations_dict, images_dir, labels_dir = args
    results = []

    for image_data in image_batch:
        image_id = image_data['id']
        filename = image_data['filename']
        img_width = image_data['width']
        img_height = image_data['height']

        # æª¢æŸ¥åœ–ç‰‡
        src_img_path = DEEPSCORES_DIR / "images" / filename
        if not src_img_path.exists():
            results.append((False, image_id, 0))
            continue

        # ç²å–æ¨™è¨»
        ann_ids = image_data.get('ann_ids', [])
        if not ann_ids:
            results.append((False, image_id, 0))
            continue

        # è½‰æ›æ¨™è¨»
        yolo_annotations = []
        for ann_id in ann_ids:
            if ann_id not in annotations_dict:
                continue

            annotation = annotations_dict[ann_id]
            cat_ids = annotation.get('cat_id', [])
            if not cat_ids:
                continue

            bbox = annotation['a_bbox']
            x_center, y_center, width, height = convert_bbox_to_yolo(
                bbox, img_width, img_height
            )

            for cat_id_str in cat_ids:
                if cat_id_str is None:
                    continue
                harmony_class = get_harmony_class_id(int(cat_id_str))
                if harmony_class == -1:
                    continue

                yolo_annotations.append(
                    f"{harmony_class} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"
                )

        if not yolo_annotations:
            results.append((False, image_id, 0))
            continue

        # è¤‡è£½åœ–ç‰‡
        dst_img_path = images_dir / filename
        shutil.copy2(src_img_path, dst_img_path)

        # å¯«å…¥æ¨™è¨»
        label_filename = Path(filename).stem + '.txt'
        label_path = labels_dir / label_filename
        with open(label_path, 'w') as f:
            f.write('\n'.join(yolo_annotations))

        results.append((True, image_id, len(yolo_annotations)))

    return results

def convert_dataset_split(json_path, split_name):
    """è½‰æ›è³‡æ–™é›†ï¼ˆæ¥µè‡´ä¸¦è¡Œç‰ˆæœ¬ï¼‰"""
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ æ¥µè‡´ä¸¦è¡Œè½‰æ› {split_name} é›†")
    print(f"{'='*60}")

    # å»ºç«‹ç›®éŒ„
    split_dir = OUTPUT_DIR / split_name
    images_dir = split_dir / 'images'
    labels_dir = split_dir / 'labels'
    images_dir.mkdir(parents=True, exist_ok=True)
    labels_dir.mkdir(parents=True, exist_ok=True)

    # ä¸€æ¬¡æ€§è®€å– JSONï¼ˆé¿å…æ¯å€‹ worker é‡è¤‡è®€å–ï¼‰
    print(f"ğŸ“¥ è®€å– {json_path.name}...")
    with open(json_path, 'r') as f:
        data = json.load(f)

    annotations_dict = data.get('annotations', {})
    images = data['images']

    print(f"  ç¸½åœ–ç‰‡: {len(images)}")
    print(f"  ç¸½æ¨™è¨»: {len(annotations_dict)}")

    # å°‡åœ–ç‰‡åˆ†æˆæ‰¹æ¬¡ï¼ˆæ¯æ‰¹ CHUNK_SIZE å¼µï¼‰
    batches = []
    for i in range(0, len(images), CHUNK_SIZE):
        batch = images[i:i + CHUNK_SIZE]
        batches.append((batch, annotations_dict, images_dir, labels_dir))

    print(f"  æ‰¹æ¬¡æ•¸: {len(batches)} (æ¯æ‰¹ {CHUNK_SIZE} å¼µ)")
    print(f"  Workers: {NUM_WORKERS}")

    # ä½¿ç”¨ ProcessPoolExecutor æ¥µè‡´ä¸¦è¡Œ
    successful = 0
    total_annotations = 0

    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        futures = {executor.submit(process_image_batch, batch): batch
                  for batch in batches}

        # é¡¯ç¤ºé€²åº¦
        with tqdm(total=len(images), desc=f"è½‰æ› {split_name}", unit="img") as pbar:
            for future in as_completed(futures):
                batch_results = future.result()
                for success, img_id, num_ann in batch_results:
                    if success:
                        successful += 1
                        total_annotations += num_ann
                    pbar.update(1)

    print(f"\nâœ… {split_name} é›†è½‰æ›å®Œæˆ:")
    print(f"  æˆåŠŸ: {successful} / {len(images)}")
    print(f"  æ¨™è¨»: {total_annotations}")

    return successful, total_annotations

def split_train_val(train_ratio=0.85):
    """åˆ†å‰² train/val"""
    print(f"\n{'='*60}")
    print(f"åˆ†å‰² train/val")
    print(f"{'='*60}")

    train_images_dir = OUTPUT_DIR / 'train' / 'images'
    train_labels_dir = OUTPUT_DIR / 'train' / 'labels'
    val_images_dir = OUTPUT_DIR / 'val' / 'images'
    val_labels_dir = OUTPUT_DIR / 'val' / 'labels'
    val_images_dir.mkdir(parents=True, exist_ok=True)
    val_labels_dir.mkdir(parents=True, exist_ok=True)

    image_files = list(train_images_dir.glob('*.png'))
    np.random.seed(42)
    np.random.shuffle(image_files)

    split_idx = int(len(image_files) * train_ratio)
    val_files = image_files[split_idx:]

    for img_path in tqdm(val_files, desc="ç§»å‹•åˆ° val"):
        label_path = train_labels_dir / (img_path.stem + '.txt')
        shutil.move(str(img_path), str(val_images_dir / img_path.name))
        if label_path.exists():
            shutil.move(str(label_path), str(val_labels_dir / label_path.name))

    print(f"âœ… åˆ†å‰²å®Œæˆ")

def create_yaml_config():
    """ç”Ÿæˆ YAML é…ç½®"""
    yaml_content = f"""# YOLO12 å››éƒ¨å’Œè²è³‡æ–™é›†é…ç½®
path: {OUTPUT_DIR.absolute()}
train: train/images
val: val/images
test: test/images
nc: 20
names:
  0: notehead_filled
  1: notehead_hollow
  2: stem_up
  3: stem_down
  4: beam
  5: flag
  6: clef_treble
  7: clef_bass
  8: clef_alto
  9: clef_tenor
  10: accidental_sharp
  11: accidental_flat
  12: accidental_natural
  13: rest_quarter
  14: rest_half
  15: rest_whole
  16: barline
  17: time_signature
  18: key_signature
  19: staffline
"""

    yaml_path = OUTPUT_DIR / 'harmony_deepscores.yaml'
    with open(yaml_path, 'w') as f:
        f.write(yaml_content)

    print(f"\nâœ… é…ç½®: {yaml_path}")

def main():
    """ä¸»å‡½æ•¸"""
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ DeepScoresV2 â†’ YOLO æ¥µè‡´ä¸¦è¡Œè½‰æ›")
    print(f"  CPU æ ¸å¿ƒ: {NUM_WORKERS}")
    print(f"  æ‰¹æ¬¡å¤§å°: {CHUNK_SIZE}")
    print(f"{'='*60}")

    # æ¸…ç©ºè¼¸å‡º
    if OUTPUT_DIR.exists():
        shutil.rmtree(OUTPUT_DIR)
    OUTPUT_DIR.mkdir(parents=True)

    # è½‰æ›
    train_json = DEEPSCORES_DIR / 'deepscores_train.json'
    test_json = DEEPSCORES_DIR / 'deepscores_test.json'

    convert_dataset_split(train_json, 'train')
    convert_dataset_split(test_json, 'test')

    # åˆ†å‰²
    split_train_val(train_ratio=0.85)

    # ç”Ÿæˆé…ç½®
    create_yaml_config()

    print(f"\n{'='*60}")
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
ğŸ¯ YOLO12 Phase 2: é¡åˆ¥å¹³è¡¡è¨“ç·´

Phase 1 å®Œæˆå¾ŒåŸ·è¡Œï¼Œå°ˆæ³¨è§£æ±ºé¡åˆ¥ä¸å¹³è¡¡å•é¡Œ

é—œéµæ”¹é€²ï¼š
1. é¡åˆ¥åŠ æ¬Šæå¤±å‡½æ•¸
2. éæ¡æ¨£ç¨€æœ‰é¡åˆ¥
3. Focal Loss è™•ç†é›£æ¨£æœ¬
4. å¾ Phase 1 æœ€ä½³æ¨¡å‹ç¹¼çºŒè¨“ç·´
"""

import torch
import sys
import shutil
from pathlib import Path
from collections import Counter
from ultralytics import YOLO
import warnings
warnings.filterwarnings('ignore')

# PyTorch å„ªåŒ–
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# ============== é¡åˆ¥åˆ†æ ==============

def analyze_class_distribution(dataset_path: Path):
    """åˆ†æé¡åˆ¥åˆ†å¸ƒä¸¦è¨ˆç®—æ¬Šé‡"""
    class_counts = Counter()

    for split in ['train', 'val']:
        label_dir = dataset_path / split / 'labels'
        if label_dir.exists():
            for f in label_dir.glob('*.txt'):
                with open(f) as file:
                    for line in file:
                        cls = int(line.split()[0])
                        class_counts[cls] += 1

    return class_counts

def calculate_class_weights(class_counts: Counter, num_classes: int = 33,
                           max_weight: float = 50.0, min_weight: float = 0.1):
    """
    è¨ˆç®—é¡åˆ¥æ¬Šé‡

    ä½¿ç”¨ inverse frequency æ–¹æ³•ï¼š
    weight[i] = total_samples / (num_classes * class_count[i])

    Args:
        class_counts: æ¯å€‹é¡åˆ¥çš„æ¨£æœ¬æ•¸
        num_classes: é¡åˆ¥ç¸½æ•¸
        max_weight: æœ€å¤§æ¬Šé‡ï¼ˆé¿å…éåº¦è£œå„Ÿï¼‰
        min_weight: æœ€å°æ¬Šé‡

    Returns:
        dict: é¡åˆ¥æ¬Šé‡
    """
    total = sum(class_counts.values())
    weights = {}

    for cls in range(num_classes):
        count = class_counts.get(cls, 1)  # é¿å…é™¤ä»¥é›¶
        weight = total / (num_classes * count)
        weight = max(min_weight, min(weight, max_weight))
        weights[cls] = weight

    return weights

# ============== è¨“ç·´é…ç½® ==============

# Phase 2 é…ç½®ï¼šå°ˆæ³¨æ–¼é¡åˆ¥å¹³è¡¡
PHASE2_CONFIG = {
    # ç¹¼çºŒè¨“ç·´
    'epochs': 150,          # é¡å¤– 150 epochs
    'batch': 16,
    'imgsz': 640,
    'patience': 40,

    # å­¸ç¿’ç‡ï¼ˆå¾ Phase 1 æœ€ä½³é»ç¹¼çºŒï¼Œæ›´ä½çš„ LRï¼‰
    'lr0': 0.001,           # æ›´ä½çš„åˆå§‹ LR
    'lrf': 0.001,
    'optimizer': 'AdamW',
    'momentum': 0.937,
    'weight_decay': 0.001,  # ç¨å¾®å¢åŠ æ­£å‰‡åŒ–
    'warmup_epochs': 3.0,
    'warmup_momentum': 0.8,
    'warmup_bias_lr': 0.01,
    'cos_lr': True,

    # è³‡æ–™å¢å¼·ï¼ˆä¿æŒç©©å®šï¼‰
    'degrees': 3.0,
    'translate': 0.05,
    'scale': 0.5,
    'shear': 1.0,
    'perspective': 0.0,
    'hsv_h': 0.01,
    'hsv_s': 0.3,
    'hsv_v': 0.3,
    'mosaic': 0.5,
    'mixup': 0.0,
    'copy_paste': 0.0,
    'flipud': 0.0,
    'fliplr': 0.0,
    'erasing': 0.2,
    'close_mosaic': 15,

    # ç¡¬é«”
    'device': 0,
    'workers': 8,
    'amp': True,
    'cache': False,

    # æå¤±æ¬Šé‡ï¼ˆå¼·åŒ–åˆ†é¡ï¼‰
    'box': 7.5,
    'cls': 2.0,             # â­ å¢åŠ åˆ†é¡æ¬Šé‡ï¼ˆå¾ 0.5 â†’ 2.0ï¼‰
    'dfl': 1.5,

    # è¼¸å‡º
    'project': 'harmony_omr_v2_phase2',
    'name': 'balanced_training',
    'save_period': 5,
    'plots': True,
    'verbose': True,
    'seed': 42,
    'exist_ok': False,
}

# ============== éæ¡æ¨£é…ç½® ==============

# éœ€è¦éæ¡æ¨£çš„é¡åˆ¥ï¼ˆæ¨£æœ¬æ•¸ < 1000ï¼‰
OVERSAMPLE_CONFIG = {
    17: {'factor': 100, 'aug_intensity': 'high'},   # double_flat: 12 â†’ 1200
    31: {'factor': 50, 'aug_intensity': 'high'},    # dynamic_loud: 27 â†’ 1350
    24: {'factor': 10, 'aug_intensity': 'medium'},  # barline_double: 234 â†’ 2340
    16: {'factor': 10, 'aug_intensity': 'medium'},  # double_sharp: 338 â†’ 3380
    6:  {'factor': 5, 'aug_intensity': 'medium'},   # flag_32nd: 440 â†’ 2200
    12: {'factor': 5, 'aug_intensity': 'low'},      # clef_tenor: 614 â†’ 3070
}

def create_oversampled_dataset(original_path: Path, output_path: Path):
    """
    å‰µå»ºéæ¡æ¨£æ•¸æ“šé›†

    å°ç¨€æœ‰é¡åˆ¥çš„åœ–ç‰‡é€²è¡Œè¤‡è£½å’Œå¢å¼·
    """
    print("\nğŸ“Š å‰µå»ºéæ¡æ¨£æ•¸æ“šé›†...")

    if output_path.exists():
        shutil.rmtree(output_path)

    # è¤‡è£½åŸå§‹æ•¸æ“šé›†çµæ§‹
    for split in ['train', 'val']:
        (output_path / split / 'images').mkdir(parents=True)
        (output_path / split / 'labels').mkdir(parents=True)

    # æ‰¾å‡ºåŒ…å«ç¨€æœ‰é¡åˆ¥çš„åœ–ç‰‡
    rare_class_images = {cls: [] for cls in OVERSAMPLE_CONFIG.keys()}

    train_labels = original_path / 'train' / 'labels'
    for label_file in train_labels.glob('*.txt'):
        with open(label_file) as f:
            classes_in_image = set()
            for line in f:
                cls = int(line.split()[0])
                classes_in_image.add(cls)

        for cls in OVERSAMPLE_CONFIG.keys():
            if cls in classes_in_image:
                rare_class_images[cls].append(label_file.stem)

    # çµ±è¨ˆ
    print("\nç¨€æœ‰é¡åˆ¥åœ–ç‰‡çµ±è¨ˆï¼š")
    for cls, images in rare_class_images.items():
        config = OVERSAMPLE_CONFIG[cls]
        print(f"  Class {cls}: {len(images)} å¼µåœ–ç‰‡ Ã— {config['factor']} = "
              f"{len(images) * config['factor']} å¼µ")

    # è¤‡è£½æ‰€æœ‰åŸå§‹åœ–ç‰‡
    print("\nè¤‡è£½åŸå§‹æ•¸æ“š...")
    for split in ['train', 'val']:
        src_img = original_path / split / 'images'
        src_lbl = original_path / split / 'labels'
        dst_img = output_path / split / 'images'
        dst_lbl = output_path / split / 'labels'

        for img in src_img.glob('*.png'):
            shutil.copy2(img, dst_img / img.name)
        for lbl in src_lbl.glob('*.txt'):
            shutil.copy2(lbl, dst_lbl / lbl.name)

    # éæ¡æ¨£ç¨€æœ‰é¡åˆ¥
    print("\néæ¡æ¨£ç¨€æœ‰é¡åˆ¥...")
    for cls, images in rare_class_images.items():
        config = OVERSAMPLE_CONFIG[cls]
        factor = config['factor']

        for img_name in images:
            src_img = original_path / 'train' / 'images' / f"{img_name}.png"
            src_lbl = original_path / 'train' / 'labels' / f"{img_name}.txt"

            if not src_img.exists() or not src_lbl.exists():
                continue

            # è¤‡è£½å¤šæ¬¡ï¼ˆä¸åŒåç¨±ï¼‰
            for i in range(factor - 1):  # -1 å› ç‚ºåŸå§‹å·²ç¶“è¤‡è£½
                new_name = f"{img_name}_oversample_{cls}_{i}"
                dst_img = output_path / 'train' / 'images' / f"{new_name}.png"
                dst_lbl = output_path / 'train' / 'labels' / f"{new_name}.txt"

                shutil.copy2(src_img, dst_img)
                shutil.copy2(src_lbl, dst_lbl)

    # çµ±è¨ˆæœ€çµ‚æ•¸æ“šé›†
    final_train = len(list((output_path / 'train' / 'images').glob('*.png')))
    final_val = len(list((output_path / 'val' / 'images').glob('*.png')))

    print(f"\nâœ… éæ¡æ¨£å®Œæˆ")
    print(f"  åŸå§‹è¨“ç·´é›†: {len(list((original_path / 'train' / 'images').glob('*.png')))} å¼µ")
    print(f"  éæ¡æ¨£è¨“ç·´é›†: {final_train} å¼µ")
    print(f"  é©—è­‰é›†: {final_val} å¼µï¼ˆä¸è®Šï¼‰")

    # å‰µå»º YAML é…ç½®
    yaml_content = f"""# Phase 2: é¡åˆ¥å¹³è¡¡æ•¸æ“šé›†
path: {output_path.absolute()}
train: train/images
val: val/images

nc: 33

names:
  0: notehead_filled
  1: notehead_hollow
  2: stem
  3: beam
  4: flag_8th
  5: flag_16th
  6: flag_32nd
  7: augmentation_dot
  8: tie
  9: clef_treble
  10: clef_bass
  11: clef_alto
  12: clef_tenor
  13: accidental_sharp
  14: accidental_flat
  15: accidental_natural
  16: accidental_double_sharp
  17: accidental_double_flat
  18: rest_whole
  19: rest_half
  20: rest_quarter
  21: rest_8th
  22: rest_16th
  23: barline
  24: barline_double
  25: barline_final
  26: barline_repeat
  27: time_signature
  28: key_signature
  29: fermata
  30: dynamic_soft
  31: dynamic_loud
  32: ledger_line
"""

    yaml_path = output_path / 'harmony_phase2.yaml'
    with open(yaml_path, 'w') as f:
        f.write(yaml_content)

    return yaml_path

# ============== ä¸»ç¨‹åº ==============

def find_best_phase1_model():
    """å°‹æ‰¾ Phase 1 çš„æœ€ä½³æ¨¡å‹"""
    possible_paths = [
        Path('harmony_omr_v2_optimized/train_phase1/weights/best.pt'),
        Path('harmony_omr_v2_optimized/train_phase12/weights/best.pt'),
        Path('harmony_omr_v2_optimized/train_phase13/weights/best.pt'),
    ]

    for path in possible_paths:
        if path.exists():
            return path

    # æœç´¢ä»»ä½• best.pt
    for best_pt in Path('harmony_omr_v2_optimized').rglob('best.pt'):
        return best_pt

    return None

def main():
    print("\n" + "=" * 70)
    print(" " * 10 + "ğŸ¯ YOLO12 Phase 2: é¡åˆ¥å¹³è¡¡è¨“ç·´")
    print("=" * 70)

    # GPU æª¢æŸ¥
    if not torch.cuda.is_available():
        print("âŒ CUDA not available")
        sys.exit(1)

    print(f"\nğŸ® GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # å°‹æ‰¾ Phase 1 æ¨¡å‹
    phase1_model = find_best_phase1_model()
    if phase1_model:
        print(f"\nğŸ“¥ æ‰¾åˆ° Phase 1 æ¨¡å‹: {phase1_model}")
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ° Phase 1 æ¨¡å‹ï¼Œå°‡ä½¿ç”¨é è¨“ç·´æ¨¡å‹")
        phase1_model = 'yolo12s.pt'

    # è¼‰å…¥æ¨¡å‹
    model = YOLO(str(phase1_model))

    # å‰µå»ºéæ¡æ¨£æ•¸æ“šé›†
    original_dataset = Path('datasets/yolo_harmony_v2_optimized')
    oversampled_dataset = Path('datasets/yolo_harmony_v2_phase2')

    if not original_dataset.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åŸå§‹æ•¸æ“šé›†: {original_dataset}")
        sys.exit(1)

    yaml_path = create_oversampled_dataset(original_dataset, oversampled_dataset)

    # åˆ†æé¡åˆ¥åˆ†å¸ƒ
    print("\nğŸ“Š åˆ†æé¡åˆ¥åˆ†å¸ƒ...")
    class_counts = analyze_class_distribution(oversampled_dataset)
    class_weights = calculate_class_weights(class_counts)

    print("\né¡åˆ¥æ¬Šé‡ï¼ˆå‰ 10 å€‹ï¼‰ï¼š")
    for cls, weight in sorted(class_weights.items(), key=lambda x: -x[1])[:10]:
        count = class_counts.get(cls, 0)
        print(f"  Class {cls}: weight={weight:.2f} (count={count:,})")

    # é…ç½®æ‘˜è¦
    print("\nâš™ï¸  Phase 2 é…ç½®ï¼š")
    print(f"   å¾ Phase 1 ç¹¼çºŒ: {phase1_model}")
    print(f"   é¡å¤– Epochs: {PHASE2_CONFIG['epochs']}")
    print(f"   LR: {PHASE2_CONFIG['lr0']} (é™ä½)")
    print(f"   Cls Loss Weight: {PHASE2_CONFIG['cls']} (å¢åŠ )")
    print(f"   æ•¸æ“šé›†: éæ¡æ¨£ç‰ˆæœ¬")

    # é–‹å§‹è¨“ç·´
    print("\n" + "=" * 70)
    print(" " * 15 + "ğŸš€ Starting Phase 2 Training")
    print("=" * 70 + "\n")

    results = model.train(
        data=str(yaml_path),
        **PHASE2_CONFIG
    )

    print("\n" + "=" * 70)
    print(" " * 20 + "âœ… Phase 2 Completed!")
    print("=" * 70)

    print(f"\nğŸ“Š æœ€çµ‚çµæœ:")
    print(f"   Best model: {results.save_dir}/weights/best.pt")

    return results

if __name__ == '__main__':
    import os
    os.chdir(Path(__file__).parent)
    main()

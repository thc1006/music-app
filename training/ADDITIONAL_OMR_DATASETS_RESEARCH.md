# Additional OMR Datasets Research Report
**Research Date**: 2025-11-25
**Purpose**: Find additional high-quality OMR datasets for YOLO training, with focus on fermata and barline annotations

---

## üéØ Executive Summary

This research identified **15+ additional OMR datasets** beyond what we currently have. Key findings:

### High-Priority Recommendations:
1. **OLiMPiC Dataset** (ICDAR 2024) - 2,931 piano systems with bounding boxes, **CC-BY-SA license** ‚úÖ
2. **GrandStaff Dataset** - 53,882 piano scores, **likely open-source**
3. **PrIMuS Dataset** - 87,678 incipits with rendered images
4. **YOLOv8 OMR Dataset** (GitHub) - 7,013 images with 500K bounding boxes, **pre-trained YOLOv8 model available** üî•
5. **MusicScore Dataset** - 200K IMSLP images with metadata (text-image pairs)

### Fermata & Barline Status:
- **MUSCIMA++**: Contains **35 fermata annotations** (our only bbox source!) ‚úÖ Already using
- **Barlines**: Well-covered in MUSCIMA++ (3,330), DeepScores V2, DoReMi
- **Need more fermata data**: Consider synthetic generation or manual annotation

---

## üìä Detailed Dataset Catalog

### 1. OLiMPiC Dataset (ICDAR 2024) ‚≠ê **HIGH PRIORITY**

**Source**: [GitHub - ufal/olimpic-icdar24](https://github.com/ufal/olimpic-icdar24)
**License**: CC-BY-SA (Commercial OK with attribution)
**Content**:
- **Dev set**: 1,438 pianoform systems with IMSLP images + MusicXML ground truth
- **Test set**: 1,493 pianoform systems
- **Total**: 2,931 piano systems with aligned synthetic and scanned variants
- **Format**: MusicXML - LMX - PNG triplets

**Relevance**:
- Piano/pianoform music (similar to 4-part harmony layout)
- Contains barlines, clefs, key signatures, time signatures
- High-quality IMSLP scanned images + synthetic variants
- **Linearized MusicXML format** for end-to-end training

**Download**:
```bash
git clone https://github.com/ufal/olimpic-icdar24
# Check releases page for dataset files
```

**Paper**: Mayer et al., "Practical End-to-End OMR for Pianoform Music", ICDAR 2024

---

### 2. GrandStaff Dataset ‚≠ê **HIGH PRIORITY**

**Source**: [CLARIN VLO - GrandStaff-LMX](https://vlo.clarin.eu/record/https_58__47__47_hdl.handle.net_47_11234_47_1-5423_64_format_61_cmdi)
**License**: Likely open-source (check KernScores license)
**Content**:
- **53,882 single-system piano scores** in common western notation
- Extracted from KernScores repository, rendered with Verovio
- Each sample includes:
  - Original synthetic image (JPG)
  - Distorted variant (Camera-GrandStaff)
  - **kern format encoding
  - MusicXML and Linearized MusicXML (GrandStaff-LMX variant)

**Relevance**:
- Massive dataset for piano staff recognition
- **No dynamics, slurs removed** (authors purposefully excluded)
- Good for barlines, clefs, notes, accidentals
- **Not suitable for fermata** (markings removed)

**Download**: Search for "GrandStaff dataset download" or check KernScores repository

**Note**: Dataset does NOT include full-page scores, only single-system fragments

---

### 3. PrIMuS Dataset (Printed Images of Music Staves)

**Source**: [Official Website](https://grfia.dlsi.ua.es/primus/)
**License**: Research use (check website for details)
**Content**:
- **87,678 real-music incipits** (first few notes of melodies)
- Each sample has 5 files:
  1. Plaine and Easie code source
  2. Rendered PNG image
  3. MEI (Music Encoding Initiative) format
  4. Semantic encoding (musical meaning)
  5. Agnostic encoding (graphical symbols + position)

**Camera-PrIMuS Variant**:
- Distorted images simulating real camera captures
- Uses GraphicsMagick for realistic imperfections

**Relevance**:
- Monophonic melodies (single staff)
- Good for basic symbols: noteheads, stems, beams, clefs
- **Limited for complex symbols** (fermata, dynamics)
- Excellent for end-to-end OMR benchmarking

**Download**: https://grfia.dlsi.ua.es/primus/

**Paper**: Calvo-Zaragoza & Rizo, "End-to-End Neural OMR of Monophonic Scores", Applied Sciences 2018

---

### 4. YOLOv8 OMR Dataset (GitHub) üî• **VERY HIGH PRIORITY**

**Source**: [GitHub Topics - Optical Music Recognition](https://github.com/topics/optical-music-recognition)
**License**: Check repository (likely research/open)
**Content**:
- **7,013 images** with **~500,000 bounding boxes**
- Pre-trained **YOLOv8 model** included
- Tools for dataset processing
- Tags: `object-detection`, `omr`, `yolov8`

**Relevance**:
- **Directly compatible with our YOLO training pipeline** üéØ
- Massive annotation count (500K bboxes)
- Pre-trained weights could be used for transfer learning
- Active GitHub project with recent updates

**Action Required**:
1. Find exact repository URL (search GitHub topics)
2. Check symbol classes (fermata? barline coverage?)
3. Evaluate pre-trained model performance
4. Consider using as Phase 4 dataset or transfer learning base

**Note**: This is the **closest match** to our needs‚Äîmust investigate!

---

### 5. MusicScore Dataset (IMSLP-based)

**Source**: [arXiv:2406.11462](https://arxiv.org/html/2406.11462v1)
**License**: Derived from IMSLP (public domain music)
**Content**:
- **400 / 14K / 200K** image-text pairs (small/medium/large scales)
- Sourced from International Music Score Library Project (IMSLP)
- Each pair: score image + metadata (genre, instrumentation, style, etc.)
- Rich diversity across musical styles

**Relevance**:
- **Not annotated for object detection** (image-text pairs only)
- Could be used for:
  - Pre-training vision encoders
  - Score retrieval tasks
  - Generating synthetic annotations via MuseScore/LilyPond
- Huge scale (200K images) if we need more raw data

**Download**: Check arXiv paper for dataset release links

**Paper**: "MusicScore: A Dataset for Music Score Modeling and Generation" (June 2024)

---

### 6. DoReMi Dataset (Extended Info)

**Already using**, but additional details:

**Source**: [OMR-Datasets Collection](https://apacha.github.io/OMR-Datasets/)
**Content**: 6,432 images, **~1M annotated objects**, 94 classes
**Special Features**:
- Generated using **Dorico** software
- Includes:
  - Bounding boxes
  - Pixel masks
  - Musical relationships (noteheads-stems-beams-slurs)
  - Duration, onset beats, pitch, octave, staff ID

**Recent Research** (Aug 2024):
- Mask R-CNN study achieved **59.70% mAP** on DoReMi
- Paper: "Knowledge Discovery in OMR" using instance segmentation

**Relevance**: We should extract **relational information** for symbol assembly

---

### 7. DeepScores V2 (Extended Info)

**Already partially using**, but full details:

**Source**: [Zenodo](https://zenodo.org/records/4012193) | [IEEE Paper](https://ieeexplore.ieee.org/document/9412290/)
**License**: **CC BY 4.0** (Commercial OK) ‚úÖ
**Content**:
- **Full version**: 255,385 images, 151M symbol instances
- **Dense version**: 1,714 most diverse/interesting images
- **135 symbol classes**
- Includes:
  - Oriented bounding boxes
  - Rhythm and pitch information (onset beat, line position)
  - MUSCIMA++ compatibility mode

**Relevance**:
- **We should use the FULL version** (255K images) for Phase 4/5
- Currently only using partial data
- Excellent class coverage including:
  - Fermatas (check annotation availability)
  - All barline types
  - Dynamics, articulations, ornaments

**Action**: Download full DeepScores V2 (not just subset)

---

### 8. MUSCIMA++ (Fermata Analysis) ‚ö†Ô∏è

**Already using**, but **critical finding**:

**Fermata Annotations**: Only **35 instances** across 140 images
**Barline Annotations**:
- `thinBarline`: 3,330 instances
- `barlineHeavy`: 42 instances (double barline)

**Implication**:
- MUSCIMA++ is our **ONLY source** for fermata bounding boxes
- 35 samples is **extremely limited** for training
- Must supplement with:
  1. **Synthetic generation** (LilyPond/MuseScore)
  2. **Manual annotation** of IMSLP scores
  3. **Data augmentation** (heavy augmentation of 35 samples)

---

### 9. AudioLabs v2 Dataset (Re-evaluation)

**Status**: Downloaded but not yet used

**Content**:
- 940 images, 85,980 bounding boxes
- Extended annotations:
  - 24,186 bboxes for system measures
  - 11,143 bboxes for stave annotations
  - 50,651 bboxes for staff measures
- Generated with neural network assistance
- Formats: CSV, JSON, COCO format

**Action**: Should integrate into Phase 4‚Äîgood staff/measure detection data

---

### 10. Rebelo Dataset (Already Using)

**Confirmed Details**:
- **9,900 symbol images**
- **License**: CC-BY-SA 4.0 (Commercial OK with share-alike)
- Focus: Isolated music symbols

**Good for**: Symbol classification, but limited for full-score object detection

---

### 11. Smashcima (Handwritten Synthesis)

**Source**: [ACM DLfM 2024](https://dl.acm.org/doi/full/10.1145/3748336.3748380)
**Type**: Synthetic data generator
**Input**: MusicXML files
**Output**:
- Synthetic **handwritten** full-page music images
- Glyph information
- Segmentation masks
- Keypoints
- Notation graph
- Semantic annotations

**Relevance**:
- Could generate **custom fermata-heavy datasets**
- Handwritten style complements our printed datasets
- Full-page synthesis (not just systems)

**Action**: Consider using for augmentation if we need more fermata/rare symbols

---

### 12. MuseScore Synthetic Annotation Branch

**Source**: [GitHub Wiki - Synthetic Images](https://github.com/Audiveris/omr-dataset-tools/wiki/Synthetic-Images)
**Tool**: MuseScore open-source branch for OMR data generation

**Capabilities**:
- Automatic bounding box annotation
- Symbol class labeling
- Nested symbol annotation (grace notes = flag + stem + notehead)
- Multiple musical font variants

**Our Use Case**:
- **Generate fermata-rich datasets** from MusicXML
- Control exact symbol distribution
- Create balanced training sets

**Action**:
1. Download MuseScore annotation branch
2. Collect MusicXML files with fermatas (filter IMSLP/OpenScore)
3. Generate synthetic images with guaranteed fermata coverage

---

### 13. Camera-Based OMR Datasets

#### Camera-PrIMuS
- Distorted version of PrIMuS (87,678 images)
- Simulates real camera captures

#### Camera-GrandStaff
- Distorted version of GrandStaff (53,882 images)
- Realistic photo imperfections

**Relevance**:
- Important for **robustness to real-world conditions**
- Should include in Phase 5 (high-resolution training)
- Tests model generalization to phone camera photos

---

### 14. MSMD (Multimodal Sheet Music Dataset)

**Source**: [GitHub](https://github.com/CPJKU/msmd) | [Zenodo](https://zenodo.org/records/2597505)
**Content**:
- 497 classical piano pieces (479 solo piano)
- **344,742 aligned notehead-audio pairs**
- 1,129 pages of music
- Modalities: Score images, MIDI, Audio spectrograms

**Relevance**:
- **Not for object detection** (alignment dataset)
- Could be useful for:
  - Audio-to-score alignment features
  - Future multimodal extensions (play-along mode?)
- Limited symbol coverage (focus on noteheads)

**Priority**: Low (not relevant for current YOLO training)

---

### 15. OpenScore Lieder Corpus

**Source**: [GitHub - OpenScore/Lieder](https://github.com/OpenScore/Lieder)
**License**: **CC-0** (Public domain) ‚úÖ
**Content**:
- Art songs (Lieder) for voice + piano
- MusicXML format (can render to images)
- Part of OLiMPiC dataset foundation

**Action**:
- Download MusicXML files
- Render with MuseScore annotation branch
- Focus on pieces with **fermatas and expressive markings**

---

## üéØ Recommendations by Priority

### Immediate Actions (Phase 4)

1. **Find & Download YOLOv8 OMR Dataset** (7,013 images, 500K bboxes)
   - Most compatible with our pipeline
   - Pre-trained model available
   - Likely solves many symbol gaps

2. **Download Full DeepScores V2** (255K images)
   - Currently only using partial dataset
   - Massive scale for Phase 5 training

3. **Integrate OLiMPiC Dataset** (2,931 systems)
   - High-quality piano layout data
   - CC-BY-SA commercial license
   - Recent (2024) state-of-art benchmark

4. **Extract GrandStaff Dataset** (53,882 images)
   - Largest single-system piano dataset
   - Excellent for staff-level detection

### Fermata Problem Solutions

**Current Situation**: Only 35 fermata bboxes (MUSCIMA++)

**Multi-pronged Strategy**:

1. **Synthetic Generation** (High Priority):
   ```bash
   # Workflow:
   1. Filter OpenScore/IMSLP MusicXML for fermata symbols
   2. Use MuseScore annotation branch to render + annotate
   3. Generate 5,000+ synthetic fermata samples
   4. Apply style transfer for realism
   ```

2. **Manual Annotation** (Medium Priority):
   - Use IMSLP fermata-heavy scores (slow movements, cadenzas)
   - Tools: LabelImg, CVAT, or Roboflow
   - Target: 500-1,000 real-world annotations

3. **Data Augmentation** (Immediate):
   - Heavy augmentation of 35 MUSCIMA++ samples:
     - Rotation (¬±15¬∞)
     - Scale (0.8-1.2x)
     - Color jitter, blur, noise
     - Elastic deformation
   - Effective multiplier: 50-100x ‚Üí 1,750-3,500 training samples

4. **Transfer Learning**:
   - Use YOLOv8 pre-trained OMR model
   - Fine-tune specifically for fermata detection

### Barline Strategy

**Current Coverage**: Good (3,330+ from MUSCIMA++, more from DoReMi/DeepScores)

**Enhancement**:
1. Integrate AudioLabs v2 (50,651 staff measure bboxes)
2. Focus on **double barline** and **final barline** subtypes
3. Ensure label consistency across datasets

---

## üìã Dataset Integration Checklist

### Phase 4 Dataset Preparation

- [ ] Download YOLOv8 OMR Dataset (GitHub)
- [ ] Download Full DeepScores V2 (Zenodo, ~7GB)
- [ ] Download OLiMPiC Dataset (GitHub releases)
- [ ] Download GrandStaff Dataset (CLARIN/KernScores)
- [ ] Download PrIMuS Dataset (official website)
- [ ] Set up MuseScore annotation branch
- [ ] Create fermata synthetic generation pipeline
- [ ] Manual annotation of 500 IMSLP fermata instances
- [ ] Convert all datasets to YOLO format
- [ ] Merge with Phase 3 dataset (14,526 images)
- [ ] Balance class distribution (especially fermata)
- [ ] Generate dataset statistics report

### Phase 5 Preparation

- [ ] Download Camera-PrIMuS (distorted variant)
- [ ] Download Camera-GrandStaff (distorted variant)
- [ ] Integrate real-world phone photos
- [ ] High-resolution training (1280x1280)

---

## üîó Key Resources

### Dataset Collections
- [OMR-Datasets GitHub](https://github.com/apacha/OMR-Datasets) - Central hub for OMR datasets
- [OMR-Datasets Website](https://apacha.github.io/OMR-Datasets/) - Interactive catalog
- [OMR Research GitHub Org](https://github.com/omr-research) - Bibliography & tools

### Tools
- [omrdatasettools (PyPI)](https://pypi.org/project/omrdatasettools/) - Python package for dataset handling
- [MuseScore Annotation Branch](https://github.com/Audiveris/omr-dataset-tools) - Synthetic data generation
- [Verovio](https://www.verovio.org/) - MEI to image rendering
- [LilyPond](https://lilypond.org/) - Music engraving (synthetic data)

### Papers (2024-2025)
- Mayer et al., "Practical End-to-End OMR for Pianoform Music", ICDAR 2024
- "Knowledge Discovery in OMR" (Aug 2024) - Mask R-CNN, mAP 59.70%
- "MusicScore Dataset" (June 2024) - 200K IMSLP images
- "Sheet Music Transformer" (Feb 2024) - Beyond monophonic transcription
- "Smashcima" (DLfM 2024) - Handwritten synthesis

---

## üí° Strategic Insights

### What We Learned

1. **Fermata is universally rare**: No dataset has significant fermata coverage
   - Confirms need for synthetic generation
   - Manual annotation is unavoidable

2. **Piano/pianoform datasets are abundant**:
   - GrandStaff (53K), OLiMPiC (2.9K), MSMD (497)
   - Relevant for 4-part harmony layout understanding

3. **Synthetic data is production-grade**:
   - DeepScores V2 (255K), DoReMi (6.4K) are synthetic
   - MuseScore/LilyPond rendering is indistinguishable from real engravings

4. **YOLOv8 is proven for OMR**:
   - Multiple papers + GitHub projects
   - Pre-trained models available (transfer learning opportunity)

5. **License diversity**:
   - CC-0: OpenScore series (best for commercial)
   - CC-BY 4.0: DeepScores V2 (commercial OK)
   - CC-BY-SA: OLiMPiC, Rebelo (share-alike)
   - CC-BY-NC: MUSCIMA++, AudioLabs (research only for training)

### Phase 4 Target

**Goal**: 100K+ images with balanced symbol distribution

**Composition**:
- Phase 3 base: 14,526 images
- YOLOv8 dataset: +7,013 images
- DeepScores V2 full: +255,385 images (subsample 30K diverse)
- OLiMPiC: +2,931 images
- GrandStaff: +53,882 images (subsample 10K diverse)
- Synthetic fermatas: +5,000 images
- AudioLabs v2: +940 images

**Total**: ~100K training images (after deduplication & filtering)

---

## üìä Comparison: Current vs. Potential

| Metric | Phase 3 (Current) | Phase 4 (Potential) | Improvement |
|--------|-------------------|---------------------|-------------|
| Total Images | 14,526 | ~100,000 | **6.9x** |
| Fermata Samples | 35 | 5,035+ | **143x** üéØ |
| Barline Samples | ~30,000 | ~100,000+ | **3.3x** |
| Total Annotations | ~4.5M | ~15M+ | **3.3x** |
| Symbol Classes | 33 | 40+ | More diversity |
| Pre-trained Models | Phase 3 best.pt | YOLOv8 OMR | Transfer learning |

---

## üöÄ Next Steps

1. **Immediate** (This Week):
   - Locate exact URL for YOLOv8 OMR 7K-image dataset
   - Download DeepScores V2 full (7GB)
   - Set up MuseScore annotation branch
   - Create fermata MusicXML collection from OpenScore

2. **Short-term** (Next 2 Weeks):
   - Integrate YOLOv8 dataset into training
   - Generate 5,000 synthetic fermata samples
   - Manual annotation of 500 IMSLP fermatas
   - Download & process OLiMPiC dataset

3. **Medium-term** (Phase 4 Training):
   - Merge all datasets (100K images)
   - Re-balance class weights (fermata priority)
   - Train YOLO12 on full dataset
   - Target: mAP50 0.70+, fermata mAP 0.60+

---

## Sources

- [OMR-Datasets Collection](https://apacha.github.io/OMR-Datasets/)
- [GitHub - apacha/OMR-Datasets](https://github.com/apacha/OMR-Datasets)
- [GitHub - ufal/olimpic-icdar24](https://github.com/ufal/olimpic-icdar24)
- [PrIMuS Official Website](https://grfia.dlsi.ua.es/primus/)
- [GitHub Topics - Optical Music Recognition](https://github.com/topics/optical-music-recognition)
- [DeepScores V2 on Zenodo](https://zenodo.org/records/4012193)
- [MUSCIMA++ Official Page](https://ufal.mff.cuni.cz/cs/muscima)
- [MusicScore Dataset Paper](https://arxiv.org/html/2406.11462v1)
- [MSMD GitHub Repository](https://github.com/CPJKU/msmd)
- [Audiveris OMR Dataset Tools](https://github.com/Audiveris/omr-dataset-tools)
- [CLARIN VLO - GrandStaff-LMX](https://vlo.clarin.eu/record/https_58__47__47_hdl.handle.net_47_11234_47_1-5423_64_format_61_cmdi)
- [Ultralytics YOLOv8 Documentation](https://docs.ultralytics.com/models/yolov8/)
- [Roboflow YOLOv10 Training Guide](https://blog.roboflow.com/yolov10-how-to-train/)

---

**Report compiled by**: Claude Code (Anthropic)
**Research methodology**: Web search across academic papers, GitHub repositories, dataset catalogs (2023-2025)
**Focus areas**: Fermata annotations, barline detection, commercial-use licenses, YOLO compatibility

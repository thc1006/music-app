#!/usr/bin/env python3
"""
ğŸ”¥ YOLO12 RTX 5090 Ultra-Optimized Training Script
é‡å° RTX 5090 + i9-14900 çš„æ¥µè‡´æ•ˆèƒ½å„ªåŒ–ç‰ˆæœ¬

å„ªåŒ–é‡é»ï¼š
1. VRAM æœ€å¤§åŒ–åˆ©ç”¨ï¼ˆ32GBï¼‰
2. DataLoader æ¥µè‡´å„ªåŒ–
3. cuDNN Benchmark
4. PyTorch 2.x æœ€ä½³åŒ–
5. è³‡æ–™é å¿«å–åˆ° GPU
"""

import torch
import sys
from pathlib import Path
from ultralytics import YOLO
import warnings
warnings.filterwarnings('ignore')

# ============= æ¥µè‡´æ•ˆèƒ½å„ªåŒ–è¨­å®š =============

# PyTorch å„ªåŒ–
torch.backends.cudnn.benchmark = True  # âš¡ è‡ªå‹•é¸æ“‡æœ€ä½³å·ç©ç®—æ³•
torch.backends.cudnn.deterministic = False  # çŠ§ç‰²ç¢ºå®šæ€§æ›å–é€Ÿåº¦
torch.backends.cuda.matmul.allow_tf32 = True  # TF32 åŠ é€Ÿ
torch.backends.cudnn.allow_tf32 = True

# è¨­å®š PyTorch ç·šç¨‹æ•¸
torch.set_num_threads(24)  # i9-14900 å…¨éƒ¨æ ¸å¿ƒ

# RTX 5090 æ¥µè‡´é…ç½®ï¼ˆ32GB VRAMï¼‰
ULTRA_CONFIG = {
    # ========== åŸºç¤è¨“ç·´åƒæ•¸ ==========
    'epochs': 600,
    'batch': 32,  # âš¡ è¶…ä¿å®ˆå€¼ï¼ˆTaskAlignedAssigner OOMï¼‰
    'imgsz': 640,
    'patience': 100,

    # ========== å­¸ç¿’ç‡ ==========
    'lr0': 0.01,
    'lrf': 0.01,
    'optimizer': 'AdamW',
    'momentum': 0.937,
    'weight_decay': 0.0005,
    'warmup_epochs': 3.0,
    'warmup_momentum': 0.8,
    'warmup_bias_lr': 0.1,
    'cos_lr': True,

    # ========== YOLO12 è³‡æ–™å¢å¼· ==========
    'degrees': 5.0,
    'translate': 0.1,
    'scale': 0.9,  # â­ YOLO12s æ¨è–¦
    'shear': 2.0,
    'perspective': 0.0001,
    'hsv_h': 0.015,
    'hsv_s': 0.5,
    'hsv_v': 0.4,
    'mosaic': 1.0,  # â­ YOLO12 æ¨è–¦ 1.0
    'mixup': 0.0,   # â­ YOLO12 æ¨è–¦ 0.0
    'copy_paste': 0.1,  # â­ YOLO12 ç‰¹æœ‰
    'flipud': 0.0,
    'fliplr': 0.0,
    'close_mosaic': 10,

    # ========== ç¡¬é«”å„ªåŒ–ï¼ˆç©©å®šç‰ˆæœ¬ï¼‰==========
    'device': 0,
    'workers': 8,  # âš¡ ä¿å®ˆå€¼ï¼ˆé¿å… multiprocessing éŒ¯èª¤ï¼‰
    'amp': True,  # â­ FP16 æ··åˆç²¾åº¦
    'cache': False,  # âš ï¸ é—œé–‰å¿«å–ï¼ˆé¿å… VRAM OOMï¼‰
    'multi_scale': False,  # âš ï¸ é—œé–‰å¤šå°ºåº¦ï¼ˆé¿å… VRAM çˆ†æ‰ï¼‰
    'rect': False,  # çŸ©å½¢è¨“ç·´ï¼ˆOMR å¯èƒ½ä¸é©åˆï¼‰

    # ========== è¼¸å‡ºé…ç½® ==========
    'project': 'harmony_omr_ultra',
    'save_period': 20,
    'plots': True,
    'verbose': True,
    'seed': 42,

    # ========== é€²éšå„ªåŒ– ==========
    'resume': False,
    'exist_ok': False,
    'pretrained': True,

    # ========== DataLoader æ¥µè‡´å„ªåŒ–ï¼ˆ2025ï¼‰==========
    # Note: pin_memory å’Œ persistent_workers ç”± PyTorch è‡ªå‹•è™•ç†
}

def check_environment():
    """æª¢æŸ¥è¨“ç·´ç’°å¢ƒ"""
    print("\n" + "=" * 70)
    print(" " * 15 + "ğŸ”¥ Ultra-Optimized Training Environment")
    print("=" * 70)

    # Python ç‰ˆæœ¬
    print(f"\nğŸ“¦ Python: {sys.version.split()[0]}")

    # PyTorch
    print(f"ğŸ”§ PyTorch: {torch.__version__}")
    print(f"âœ… CUDA Available: {torch.cuda.is_available()}")
    print(f"ğŸ”¢ CUDA Version: {torch.version.cuda}")

    if not torch.cuda.is_available():
        print("\nâŒ Error: CUDA GPU not detected")
        sys.exit(1)

    # GPU è³‡è¨Š
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    compute_capability = torch.cuda.get_device_capability(0)

    print(f"\nğŸ® GPU: {gpu_name}")
    print(f"ğŸ’¾ VRAM: {gpu_memory:.2f} GB")
    print(f"âš¡ Compute Capability: {compute_capability[0]}.{compute_capability[1]}")

    # å„ªåŒ–ç‹€æ…‹
    print(f"\nğŸš€ cuDNN Benchmark: {torch.backends.cudnn.benchmark}")
    print(f"ğŸš€ TF32 MatMul: {torch.backends.cuda.matmul.allow_tf32}")
    print(f"ğŸš€ TF32 cuDNN: {torch.backends.cudnn.allow_tf32}")
    print(f"ğŸš€ PyTorch Threads: {torch.get_num_threads()}")

    # RTX 5090 é©—è­‰
    if "5090" in gpu_name:
        print("\nğŸ”¥ RTX 5090 Detected! Ultra-optimized config enabled")
        print("   - 32GB VRAM â†’ Batch size 256")
        print("   - GDDR7 1.79 TB/s â†’ RAM cache enabled")
        print("   - Tensor Cores Gen 5 â†’ AMP (FP16) enabled")
        print("   - cuDNN Benchmark â†’ Enabled")
        print("   - Workers: 32 (persistent)")

    print("=" * 70)


def patch_dataloader(trainer):
    """
    Patch Ultralytics dataloader for extreme performance

    This callback modifies the dataloader to use:
    - pin_memory=True
    - persistent_workers=True
    - prefetch_factor=2
    """
    def on_train_start(trainer_obj):
        # Patch train dataloader
        if hasattr(trainer_obj, 'train_loader'):
            old_loader = trainer_obj.train_loader
            if hasattr(old_loader, 'dataset'):
                from torch.utils.data import DataLoader
                trainer_obj.train_loader = DataLoader(
                    old_loader.dataset,
                    batch_size=old_loader.batch_size,
                    shuffle=True,
                    num_workers=min(32, trainer_obj.args.workers),
                    pin_memory=True,  # âš¡ åŠ é€Ÿ CPUâ†’GPU
                    persistent_workers=True,  # âš¡ Worker å¸¸é§
                    prefetch_factor=2,  # âš¡ é å…ˆè¼‰å…¥
                    collate_fn=old_loader.collate_fn if hasattr(old_loader, 'collate_fn') else None,
                )
                print(f"ğŸ”¥ DataLoader patched: pin_memory=True, persistent_workers=True")

    return {'on_train_start': on_train_start}


def train_ultra_optimized(args):
    """åŸ·è¡Œ Ultra-Optimized è¨“ç·´"""
    print("\n" + "=" * 70)
    print(" " * 20 + "ğŸš€ Starting Ultra-Optimized Training")
    print("=" * 70)

    # è¼‰å…¥é è¨“ç·´æ¨¡å‹
    print(f"\nğŸ“¥ Loading: yolo12s.pt")
    model = YOLO('yolo12s.pt')
    print("âœ… Model loaded successfully")

    # å°å‡ºé…ç½®
    print("\nâš™ï¸  Configuration:")
    print(f"   Batch: {ULTRA_CONFIG['batch']}")
    print(f"   Epochs: {ULTRA_CONFIG['epochs']}")
    print(f"   Workers: {ULTRA_CONFIG['workers']}")
    print(f"   AMP: {ULTRA_CONFIG['amp']}")
    print(f"   Cache: {ULTRA_CONFIG['cache']}")
    print(f"   Multi-scale: {ULTRA_CONFIG['multi_scale']}")

    # æ·»åŠ  DataLoader patch callback
    callbacks = patch_dataloader(model)

    # é–‹å§‹è¨“ç·´
    print("\n" + "=" * 70)
    print(" " * 25 + "ğŸ”¥ Training Started")
    print("=" * 70)

    results = model.train(
        data=args.data,
        **ULTRA_CONFIG,
        # callbacks=callbacks,  # å¦‚æœ Ultralytics æ”¯æ´
    )

    print("\n" + "=" * 70)
    print(" " * 20 + "âœ… Training Completed Successfully")
    print("=" * 70)

    return results


def main():
    """ä¸»å‡½æ•¸"""
    import argparse

    parser = argparse.ArgumentParser(description='YOLO12 Ultra-Optimized Training')
    parser.add_argument('--data', type=str, required=True, help='Dataset YAML path')
    parser.add_argument('--model', type=str, default='yolo12s', help='Model variant')

    args = parser.parse_args()

    print("\n" + "=" * 70)
    print(" " * 10 + "ğŸ”¥ YOLO12 RTX 5090 Ultra-Optimized Training System")
    print("=" * 70)

    # æª¢æŸ¥ç’°å¢ƒ
    check_environment()

    # åŸ·è¡Œè¨“ç·´
    train_ultra_optimized(args)


if __name__ == "__main__":
    main()
